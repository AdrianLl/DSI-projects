{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michelin red guide project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://bit.ly/1OX13uv\" width=\"350\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://bit.ly/1OX13uv', width=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import great_circle\n",
    "import time\n",
    "\n",
    "from IPython.core.display import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import statsmodels.api as st\n",
    "import sklearn\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import cross_validation, preprocessing\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.patheffects as path_effects\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates (as a list) and saves (as a dataframe) the path for each restaurant site; switch to 'code' if necessary to run it again:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "big_URL = 'http://www.viamichelin.com/web/Restaurants?geoboundaries=-59.1759282,-82.96875:82.166446,55.546875'\n",
    "page_URL = '&page='\n",
    "\n",
    "paths = []\n",
    "for page in range(2,775):\n",
    "    pre_mich = requests.get(big_URL + page_URL + str(page))\n",
    "    pre_soup = BeautifulSoup(pre_mich.content, \"lxml\")\n",
    "    for restaurant in pre_soup.find_all('a', href=re.compile('/web/Restaurant/')):\n",
    "        path = restaurant[\"href\"]\n",
    "        paths.append(path)\n",
    "\n",
    "paths = pd.DataFrame(paths)\n",
    "paths.columns = ['path']\n",
    "paths.to_csv('assets/michelin_paths___RENAME_ME____.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to load the dataframe created immediately above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = pd.read_csv('/Users/Rebecca/DSI-projects/projects/capstone/assets/michelin_paths.csv')\n",
    "paths = paths['0']\n",
    "paths.reset_index(drop = True)\n",
    "paths.columns = ['path']\n",
    "\n",
    "test_paths = paths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/web/Restaurant/Penmarch-29760-Sterenn-12822-41102'\n",
      "'/web/Restaurant/Saint_Jean_Cap_Ferrat-06230-Le_Cap-12838-41102'\n",
      "'/web/Restaurant/Saint_Jean_Cap_Ferrat-06230-La_Voile_d_Or-12839-41102'\n",
      "'/web/Restaurant/St_Jean_du_Bruel-12230-Midi_Papillon-12855-41102'\n",
      "'/web/Restaurant/Saint_Jean_Pied_de_Port-64220-Les_Pyrenees-12858-41102'\n",
      "'/web/Restaurant/Saint_Laurent_de_Mure-69720-Christian_Lavault-12878-41102'\n",
      "'/web/Restaurant/Saint_Leonard_de_Noblat-87400-Le_Relais_St_Jacques-12885-41102'\n",
      "'/web/Restaurant/St_Malo-35400-La_Grassinais-12895-41102'\n",
      "'/web/Restaurant/Tilques-62500-Chateau_Tilques-12915-41102'\n",
      "'/web/Restaurant/Saint_Pons-07580-Hostellerie_Gourmande_Mere_Biquette-12938-41102'\n"
     ]
    }
   ],
   "source": [
    "URL = 'http://www.viamichelin.com'\n",
    "for i in test_paths:\n",
    "    print '\\'' + i + '\\''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to scrape and organize data from the restaurant sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def restaurantify(path_list):\n",
    "    \n",
    "    '''This function creates a dataframe with restaurant observations and columns containing relevant information.'''\n",
    "    \n",
    "    URL = 'http://www.viamichelin.com'\n",
    "\n",
    "    name = []\n",
    "    address = []\n",
    "    cuisine = []\n",
    "    blurb = []\n",
    "    price = []\n",
    "    author = []\n",
    "    distinction = []\n",
    "    standing = []\n",
    "    photo = []\n",
    "    add_info = []\n",
    "\n",
    "\n",
    "    for i in path_list:\n",
    "        time.sleep(5)\n",
    "        tiny_request = requests.get(URL + i)\n",
    "        if str(tiny_request) != '<Response [200]>':\n",
    "            print URL + i\n",
    "        tiny_soup = BeautifulSoup(tiny_request.content, \"lxml\")\n",
    "        \n",
    "        for rest_name in tiny_soup.findAll('div', class_ = 'datasheet-item datasheet-name'):\n",
    "            name.append(rest_name.text)\n",
    "        \n",
    "        for rest_address in tiny_soup.findAll('div', class_ = 'datasheet-item'):\n",
    "            name.append(rest_name.text)\n",
    "        \n",
    "        for rest_cuisine in tiny_soup.findAll('div', class_ = 'datasheet-cooking-type'):\n",
    "            cuisine.append(rest_cuisine.text)\n",
    "        \n",
    "        for rest_blurb in tiny_soup.findAll('div', class_ = 'datasheet-description'):\n",
    "            for j in rest_blurb.find_all('blockquote'):\n",
    "                blurb.append(j.text)\n",
    "        \n",
    "        for rest_price in tiny_soup.findAll('div', class_ = 'datasheet-price'):\n",
    "            price.append(rest_price.text)\n",
    "    \n",
    "        for rest_author in tiny_soup.findAll('p', class_ = 'michelin-guide-inspectors'):\n",
    "            author.append(rest_author.text)\n",
    "    \n",
    "        for rest_distinction in tiny_soup.findAll('div', class_ = 'poi-item-stars'):\n",
    "            for j in rest_distinction.find_all('span'):\n",
    "                distinction.append(j['class'])\n",
    "        \n",
    "        for rest_standing_raw in tiny_soup.findAll('span', class_=re.compile('standing')):\n",
    "            rest_standing = rest_standing_raw['class']\n",
    "            standing.append(rest_standing)\n",
    "        \n",
    "        for rest_photo in tiny_soup.findAll('div', class_ = 'datasheet-more-info datasheet-photo clearfx'):\n",
    "            photo.append(rest_photo.text[0:13])\n",
    "            \n",
    "        for rest_add_info in tiny_soup.findAll('div', class_ = 'datasheet-more-info clearfx'):\n",
    "            add_info.append(rest_add_info.text)\n",
    "    \n",
    "    print len(name)\n",
    "    print len(address)\n",
    "    print len(cuisine)\n",
    "    print len(blurb)\n",
    "    print len(price)\n",
    "    print len(author)\n",
    "    print len(distinction)\n",
    "    print len(standing)\n",
    "    print len(photo)\n",
    "    print len(add_info)\n",
    "    df = pd.DataFrame(zip(name, address, cuisine, blurb, price, author, distinction, standing, photo, add_info),\\\n",
    "                        columns = ['name', 'address', 'cuisine', 'blurb', 'price', 'author', 'distinction', \\\n",
    "                                   'standing', 'photo', 'add_info']) \n",
    "    print len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='www.viamichelin.comw', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x1178dcc10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-00c497ad19dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrestaurantify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/web/Restaurant/Penmarch-29760-Sterenn-12822-41102'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d26b7804c1b5>\u001b[0m in \u001b[0;36mrestaurantify\u001b[0;34m(path_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtiny_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiny_request\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<Response [200]>'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rebecca/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rebecca/anaconda/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rebecca/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    466\u001b[0m         }\n\u001b[1;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rebecca/anaconda/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rebecca/anaconda/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='www.viamichelin.comw', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x1178dcc10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known',))"
     ]
    }
   ],
   "source": [
    "restaurantify('/web/Restaurant/Penmarch-29760-Sterenn-12822-41102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tSterenn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request = requests.get(URL + test_paths[0])\n",
    "if str(request) != '<Response [200]>':\n",
    "    print 'bad connection'\n",
    "tiny_soup = BeautifulSoup(request.content, \"lxml\")\n",
    "for i in tiny_soup.findAll('div', class_ = 'datasheet-item datasheet-name'):\n",
    "    print i.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape and organize data using restaurantify() on list of site paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /web/Restaurant/Penmarch-29760-Sterenn-12822-4...\n",
       "1    /web/Restaurant/Saint_Jean_Cap_Ferrat-06230-Le...\n",
       "2    /web/Restaurant/Saint_Jean_Cap_Ferrat-06230-La...\n",
       "3    /web/Restaurant/St_Jean_du_Bruel-12230-Midi_Pa...\n",
       "4    /web/Restaurant/Saint_Jean_Pied_de_Port-64220-...\n",
       "5    /web/Restaurant/Saint_Laurent_de_Mure-69720-Ch...\n",
       "6    /web/Restaurant/Saint_Leonard_de_Noblat-87400-...\n",
       "7    /web/Restaurant/St_Malo-35400-La_Grassinais-12...\n",
       "8    /web/Restaurant/Tilques-62500-Chateau_Tilques-...\n",
       "9    /web/Restaurant/Saint_Pons-07580-Hostellerie_G...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\tLe Cap\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "little_mess[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mich.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mich.to_csv('michelin.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mich = pd.read_csv('/Users/Rebecca/DSI-projects/projects/capstone/michelin.csv')\n",
    "\n",
    "columns = ['name', 'address', 'cuisine', 'price', 'blurb', 'author', 'distinction', 'standing', 'photos', 'add_info']\n",
    "\n",
    "mich = mich[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        object\n",
       "address     object\n",
       "cuisine     object\n",
       "price       object\n",
       "blurb       object\n",
       "author      object\n",
       "award       object\n",
       "rank        object\n",
       "photos      object\n",
       "add_info    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mich.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mich.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mich['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_name(df):\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('\\n\\t', ''))\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('\\n', ''))\n",
    "    return df\n",
    "\n",
    "def clean_cuisine(df):\n",
    "    test_mich['cuisine'] = test_mich['cuisine'].apply(lambda x: x.replace('|', ' '))\n",
    "    test_mich['cuisine'] = test_mich['cuisine'].apply(lambda x: x.replace('Cuisine', ''))\n",
    "    test_mich['cuisine'] = test_mich['cuisine'].apply(lambda x: x.replace('cuisine', ''))\n",
    "    return df\n",
    "\n",
    "def split_price(df):\n",
    "    df['price'] = df['price'].apply(lambda x: x.replace('\\n\\t\\t\\tFrom ', ''))\n",
    "    df['price'] = df['price'].apply(lambda x: x.replace('\\n\\t\\t\\t', ' '))\n",
    "    df['price'] = df['price'].apply(lambda x: x.replace('\\n', ''))\n",
    "    low_price = []\n",
    "    high_price = []\n",
    "    anything = []\n",
    "    for pricerange in df['price']:\n",
    "        pricerange = pricerange.split(' to ')\n",
    "        low_price.append(pricerange[0])\n",
    "        high_price.append(pricerange[1])\n",
    "        if len(address) > 2:\n",
    "            anything.append(pricerange[2])\n",
    "    df['low_price'] = low_price        \n",
    "    df['high_price'] = high_price\n",
    "    if len(anything) == 0:\n",
    "        print 'All addresses split correctly by comma!'\n",
    "        del df['price']\n",
    "    else: \n",
    "        print 'We have a problem!  Not all addresses split correctly by comma!'\n",
    "    return df\n",
    "\n",
    "def split_address(df):\n",
    "    street_address = []\n",
    "    general_location = []\n",
    "    anything = []\n",
    "    for address in df['address']:\n",
    "        address = address.split(',')\n",
    "        street_address.append(address[0])\n",
    "        general_location.append(address[1])\n",
    "        if len(address) > 2:\n",
    "            anything.append(address[2])\n",
    "    df['street_address'] = street_address\n",
    "    df['general_location'] = general_location\n",
    "    if len(anything) == 0:\n",
    "        print 'All addresses split correctly by comma!'\n",
    "        del df['address']\n",
    "    else:\n",
    "        print 'We have a problem!  Not all addresses split correctly by comma!'\n",
    "    return df\n",
    "\n",
    "def clean_blurb(df):\n",
    "    df['blurb'] = df['blurb'].apply(lambda x: x.replace('\\n\\nMICHELIN Guide\\n\\n\\t\\t\\t', ''))\n",
    "    return df\n",
    "\n",
    "def get_standing(df):\n",
    "    df['standing'] = df['standing'].apply(lambda x: x.replace('[\\'standing-', ''))\n",
    "    df['standing'] = df['standing'].apply(lambda x: x.replace('\\']', ''))\n",
    "    return df\n",
    "\n",
    "def get_distinction(df):\n",
    "    df['distinction'] = df['distinction'].apply(lambda x: x.replace('[\\'', ''))\n",
    "    df['distinction'] = df['distinction'].apply(lambda x: x.replace('\\']', ''))\n",
    "    return df\n",
    "\n",
    "def get_photos(df):\n",
    "    df['photos'] = df['photos'].apply(lambda x: x.replace('\\nPhoto (', ''))\n",
    "    df['photos'] = df['photos'].apply(lambda x: x.replace('\\nPhotos (', ''))\n",
    "    test_mich['photos'] = test_mich['photos'].apply(lambda x: x.replace(')', ''))\n",
    "    test_mich['photos'] = test_mich['photos'].apply(lambda x: int(x.replace('\\n', '')))\n",
    "    return df\n",
    "\n",
    "def get_where(df):\n",
    "    location = []\n",
    "    location_info = []\n",
    "    lat_lon = []\n",
    "    geolocator = Nominatim()\n",
    "    for street in df['street_address']:\n",
    "        location = geolocator.geocode(street)\n",
    "        location.append(location.address)\n",
    "        location_info.append(location.raw)\n",
    "        lat_lon.append('(' + str(location.latitude) + ', ' + str(location.longitude) + ')')\n",
    "    df['location'] = location\n",
    "    df['lat_lon'] = lat_lon\n",
    "    df['location_info'] = location_info\n",
    "    return df\n",
    "\n",
    "def how_far_to_people(df):\n",
    "    nearest_people = []\n",
    "    for i in range(len(df['town'])):\n",
    "        eat = df['lat_lon'][i]\n",
    "        people = df[''][i]\n",
    "        too_far = great_circle(eat, people).kilometers\n",
    "        nearest_people.append(too_far)\n",
    "    df['nearest_people'] = nearest_people\n",
    "    return df\n",
    "\n",
    "def split_blurb(df):\n",
    "    blurb = []\n",
    "    not_blurb = []\n",
    "    for bigblurb in df['blurb']:\n",
    "        \n",
    "    df['blurb'] = blurb\n",
    "    return df\n",
    "\n",
    "def blurb_count(df):\n",
    "    word_count = []\n",
    "    for i in df['blurb']:\n",
    "        x = i.split(' ')\n",
    "        count = len(x)\n",
    "        word_count.append(count)\n",
    "    df['word_count'] = word_count\n",
    "    return df\n",
    "\n",
    "def get_range(df):\n",
    "    price_range = []\n",
    "    for i in range(len(df)):\n",
    "        pricerange = df['high_price'][i] - df['low_price'][i]\n",
    "        price_range.append(pricerange)\n",
    "    df['price_range'] = price_range\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_where(df):\n",
    "    location = []\n",
    "    location_info = []\n",
    "    lat_lon = []\n",
    "    geolocator = Nominatim()\n",
    "    for street in df['street_address']:\n",
    "        location = geolocator.geocode(street)\n",
    "        location.append(location.address)\n",
    "        location_info.append(location.raw)\n",
    "        lat_lon.append('(' + str(location.latitude) + ', ' + str(location.longitude) + ')')\n",
    "    df['location'] = location\n",
    "    df['lat_lon'] = lat_lon\n",
    "    df['location_info'] = location_info\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####  TESTING CELL\n",
    "\n",
    "pre_request = requests.get('http://www.viamichelin.com/' + '')\n",
    "pre_soup = BeautifulSoup(pre_request.content, 'lxml')\n",
    "\n",
    "mess_list = []\n",
    "for mess in pre_soup.find_all('div', class_ = 'datasheet-item'):\n",
    "    print type(mess)\n",
    "#    mess_list.append(mess[0].text.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mich = restaurantify(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>little_mess</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>price</th>\n",
       "      <th>blurb</th>\n",
       "      <th>author</th>\n",
       "      <th>distinction</th>\n",
       "      <th>standing</th>\n",
       "      <th>photos</th>\n",
       "      <th>add_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [little_mess, cuisine, price, blurb, author, distinction, standing, photos, add_info]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mich.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /web/Restaurant/Penmarch-29760-Sterenn-12822-4...\n",
       "1    /web/Restaurant/Saint_Jean_Cap_Ferrat-06230-Le...\n",
       "2    /web/Restaurant/Saint_Jean_Cap_Ferrat-06230-La...\n",
       "3    /web/Restaurant/St_Jean_du_Bruel-12230-Midi_Pa...\n",
       "4    /web/Restaurant/Saint_Jean_Pied_de_Port-64220-...\n",
       "5    /web/Restaurant/Saint_Laurent_de_Mure-69720-Ch...\n",
       "6    /web/Restaurant/Saint_Leonard_de_Noblat-87400-...\n",
       "7    /web/Restaurant/St_Malo-35400-La_Grassinais-12...\n",
       "8    /web/Restaurant/Tilques-62500-Chateau_Tilques-...\n",
       "9    /web/Restaurant/Saint_Pons-07580-Hostellerie_G...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location((47.7982044, -4.37276110875, 0.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode('Route d\\'Eckmuhl')\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tLe Cap\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "URL = 'http://www.viamichelin.com'\n",
    "little_mess = []\n",
    "for i in test_paths:\n",
    "    tiny_request = requests.get(URL + i)\n",
    "    if str(tiny_request) != '<Response [200]>':\n",
    "        print tiny_request\n",
    "    tiny_soup = BeautifulSoup(tiny_request.content, \"lxml\")\n",
    "    for mess in tiny_soup.find_all('div', class_ = 'datasheet-item'):\n",
    "            little_mess.append(str(mess.text.encode('utf8')))\n",
    "print little_mess[3]\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
